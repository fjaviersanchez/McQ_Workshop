{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline \n",
    "#This is an ipython magic to import numpy and matplotlib (to produce graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import astropy.io.fits as fits #This library handles FITS files (There are other libraries to do so in python as well)\n",
    "from skimage.morphology import disk\n",
    "from skimage.filters import rank\n",
    "from astropy.visualization import make_lupton_rgb\n",
    "from reproject import reproject_interp, reproject_exact\n",
    "from photutils import CircularAperture\n",
    "from photutils import aperture_photometry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the original images that you took"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "science_image_path_g = 'data/seo_m66_g-band_180s_apagul_1.fits' #Type the path to your image\n",
    "sci_g = fits.open(science_image_path_g)\n",
    "sci_im_g = fits.open(science_image_path_g)[0].data\n",
    "plt.imshow(sci_im_g,cmap='gray', vmax=1800, norm=matplotlib.colors.LogNorm())\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This image is not science-ready yet...\n",
    "\n",
    "Dark image: If you take a shot with the shutter closed (i.e., no light/photons incoming in the camera) you still have a non-zero image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dark_image_path='data/dark.fits' #Type the path to your dark image\n",
    "drk_im = fits.open(dark_image_path)[0].data\n",
    "plt.imshow(drk_im,cmap='gray', vmax=2000)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bias_image_path = 'data/bias.fits' #Type the path to your bias image\n",
    "bias_image = fits.open(bias_image_path)[0].data\n",
    "plt.imshow(bias_image, cmap='gray')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(drk_im.flatten());\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Output counts')\n",
    "plt.ylabel('Number of pixels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why is this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another interesting feature of CCD cameras is that the chips do not respond equally to the same light intensity. For example if you illuminate the camera with uniform light (this is called *flat* image). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flat_image_path = 'data/FLAT_g-band_2016-10-06_bin1_id5908.fits' #Type the path to your flat image here\n",
    "flat_image = fits.open(flat_image_path)[0].data\n",
    "#You can try cmap='hot' or cmap='jet' to see how it changes\n",
    "plt.imshow(flat_image, cmap='gray') \n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(flat_image.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reduce_image(sci_im,drk_im,flat_im, bias_im, filter_dark=True):\n",
    "    from scipy.stats import mode\n",
    "    dkr_im = drk_im - bias_im\n",
    "    #First part: We take \"zero\" the image\n",
    "    #The next part is optional and averages the dark image in a 10 pixel radius\n",
    "    #to get rid of salt/pepper noise\n",
    "    if(filter_dark):\n",
    "        selem = disk(10) #We are going to perform averages in 10 pixel radius disks\n",
    "        selem2 = disk(4)\n",
    "        drk_im = rank.mean(drk_im, selem=selem) #We perform an average to remove salt-pepper noise\n",
    "        flat_im = rank.mean(flat_im, selem=selem2)\n",
    "    #Second part: Make every part have the same sensitivity\n",
    "    #flat_im = (flat_im - drk_im)/mode(flat_im-drk_im,axis=None)[0] #most common pixel value will equal 1\n",
    "    flat_im = (flat_im - drk_im)/np.median(flat_im-drk_im)\n",
    "    #Lower than 1 where the CCD is less sensitive and more than 1 where it's more sensitive\n",
    "    sci_im = (sci_im -drk_im)/flat_im\n",
    "    #Error image\n",
    "    return sci_im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a better image!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_sci_image_g = reduce_image(sci_im_g,drk_im,flat_image,bias_image, filter_dark=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(new_sci_image_g, cmap='gray', vmax=4000, vmin=50, norm=matplotlib.colors.LogNorm())\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare to the original!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1,ncols=3,figsize=(10,8))\n",
    "ax[0].imshow(sci_im_g,cmap='gray',vmax=1800, norm=matplotlib.colors.LogNorm())\n",
    "ax[0].set_title('Before reduction')\n",
    "ax[1].imshow(new_sci_image_g,cmap='gray',vmax=2000, vmin=50, norm=matplotlib.colors.LogNorm())\n",
    "ax[1].set_title('After reduction')\n",
    "ax[2].imshow(sci_im_g-new_sci_image_g,cmap='gray', vmax=1050, vmin=1000)\n",
    "ax[2].set_title('Difference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "science_image_path_r = 'data/seo_m66_r_180s_apagul_1.fits' \n",
    "sci_im_r = fits.open(science_image_path_r)[0].data\n",
    "science_image_path_i = 'data/seo_m66_i-band_180s_apagul_1.fits'\n",
    "sci_im_i = fits.open(science_image_path_i)[0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flat_r = fits.open('data/FLAT_r-band_2016-10-06_bin1_id5906.fits')[0].data\n",
    "flat_i = fits.open('data/FLAT_i-band_2016-10-06_bin1_id5907.fits')[0].data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduce the rest of images (in principle we should take a different bias image for each filter) because the CCD has different sensitivity at different wavelengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_sci_image_r = reduce_image(sci_im_r,drk_im,flat_r,bias_image)\n",
    "new_sci_image_i = reduce_image(sci_im_i,drk_im,flat_i,bias_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example from SDSS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in the three images downloaded from here:\n",
    "# g: http://dr13.sdss.org/sas/dr13/eboss/photoObj/frames/301/1737/5/frame-g-001737-5-0039.fits.bz2\n",
    "# r: http://dr13.sdss.org/sas/dr13/eboss/photoObj/frames/301/1737/5/frame-r-001737-5-0039.fits.bz2\n",
    "# i: http://dr13.sdss.org/sas/dr13/eboss/photoObj/frames/301/1737/5/frame-i-001737-5-0039.fits.bz2\n",
    "g = fits.open('data/frame-g-001737-5-0039.fits.bz2')[0]\n",
    "r = fits.open('data/frame-r-001737-5-0039.fits.bz2')[0]\n",
    "i = fits.open('data/frame-i-001737-5-0039.fits.bz2')[0]\n",
    "\n",
    "# remap r and i onto g\n",
    "r_new, r_mask = reproject_interp(r, g.header)\n",
    "i_new, i_mask = reproject_interp(i, g.header)\n",
    "\n",
    "# zero out the unmapped values\n",
    "i_new[np.logical_not(i_mask)] = 0\n",
    "r_new[np.logical_not(r_mask)] = 0\n",
    "\n",
    "# red=i, green=r, blue=g\n",
    "# make a file with the default scaling\n",
    "rgb_default = make_lupton_rgb(i_new, r_new, g.data, filename=\"ngc6976-default.jpeg\")\n",
    "# this scaling is very similar to the one used in Lupton et al. (2004)\n",
    "rgb = make_lupton_rgb(i_new, r_new, g.data, Q=10, stretch=0.5, filename=\"ngc6976.jpeg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to know more about Jupyter:\n",
    "https://github.com/fjaviersanchez/JupyterTutorial/blob/master/TutorialJupyter.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperture photometry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Astronomers use the magnitude scale to characterize the bright of an object. With the magnitude scale you quantify the brightness of an object by comparing it with other objects. Astronomers have agreed to use \"Vega\" as the zero magnitude point (like the freezing point for water is the zero-point for the Celsius temperature scale). The magnitude scale goes \"backwards\" in the sense that brighter objects have smaller magnitude. For example the Sun has magnitude -27, the full Moon -13, and Venus -5. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we measure magnitudes from an image?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A first approach is to use an object which magnitude we know, called \"standard\" and refer the rest of the objects in an image to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what do you use to count the total brightness of an object?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use the brightest pixel?\n",
    "* Add the brightness in a certain radius?\n",
    "* Count only the pixels which belong to each object?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "positions = [(550., 600.), (450., 500.)] #Change it and include the position of an object in your image\n",
    "apertures = CircularAperture(positions, r=20.)\n",
    "phot_table = aperture_photometry(new_sci_image_g, apertures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print phot_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Astronomers use both disks and complicated shapes to measure the brightness and they then refer to a known object!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
